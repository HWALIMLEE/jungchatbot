{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/90/18ac0e5340b6228c25cc8e79835c3811e7553b2b9ae87296dfeb62b7866d/tldextract-2.2.1-py2.py3-none-any.whl (48kB)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from newspaper3k) (5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from newspaper3k) (2.8.0)\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from newspaper3k) (4.7.1)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from newspaper3k) (2.21.0)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from newspaper3k) (4.3.2)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from newspaper3k) (3.4.3)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from newspaper3k) (5.4.1)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (2.8)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (41.0.1)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/23/9c/6e63c23c39e53d3df41c77a3d05a49a42c4e1383a6d2a5e3233161b89dbf/requests_file-1.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from python-dateutil>=2.5.3->newspaper3k) (1.12.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (1.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\finance\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2019.6.16)\n",
      "Building wheels for collected packages: tinysegmenter, jieba3k, feedfinder2\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\student\\AppData\\Local\\pip\\Cache\\wheels\\81\\2b\\43\\a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\student\\AppData\\Local\\pip\\Cache\\wheels\\83\\15\\9c\\a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\student\\AppData\\Local\\pip\\Cache\\wheels\\de\\03\\ca\\778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
      "Successfully built tinysegmenter jieba3k feedfinder2\n",
      "Installing collected packages: feedparser, requests-file, tldextract, tinysegmenter, jieba3k, cssselect, feedfinder2, newspaper3k\n",
      "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.4.3 tinysegmenter-0.3 tldextract-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.tag import Twitter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청년 내일채움공제, 중소·중견기업 근속 청년 공제 사업…신청방법은?\n",
      "0 청년 내일채움공제에 관심이 쏠리고 있다. /청년 내일채움공제 홈페이지 아시아투데이 서현정 기자 = 2일 '청년 내일채움공제'가 주목받고 있다. 아시아투데이 서현정 기자 = 2일 '청년 내일채움공제'가 주목받고 있다.\n",
      "\n",
      "'청년 내일채움공제'란 중소·중견기업에 정규직으\n"
     ]
    }
   ],
   "source": [
    "#크롤링할 url 주소 입력\n",
    "url = 'http://www.asiatoday.co.kr/view.php?key=20190802000725171'\n",
    "#언어가 한국어이므로 language='ko'로 설정\n",
    "a = Article(url, language='ko')\n",
    "a.download()\n",
    "a.parse()\n",
    "#기사 제목 가져오기\n",
    "print(a.title)\n",
    "#기사 내용 가져오기(150자)\n",
    "print(a.text[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"0 청년 내일채움공제에 관심이 쏠리고 있다. /청년 내일채움공제 홈페이지 아시아투데이 서현정 기자 = 2일 '청년 내일채움공제'가 주목받고 있다. 아시아투데이 서현정 기자 = 2일 '청년 내일채움공제'가 주목받고 있다.\\n\\n'청년 내일채움공제'란 중소·중견기업에 정규직으로 취업한 청년들의 장기근속을 위해 고용노동부와 중소벤처기업부가 공동으로 운영하는 정책성 공제사업이다.\\n\\n사업은 청년·기업·정부가 공동으로 공제금을 적립하여 2년 또는 3년간 근속한 청년에게 성과보상금 형태로 만기공제금을 지급하는 식으로 운영된다.\\n\\n청년 가입조건은 정규직 취업일 나이 만 15세 이상 34세 이하 해당 자이며, 정규직 취업일 현재 고용보험 이력이 없거나 최종학교 졸업 후 이전 직장까지의 고용보험 총 가입기간이 12개월 이하인 자이다.\\n\\n고등학교 및 대학 재학 중인 자, 청년공제에 가입했던 자, 월 급여총액이 500만원 초과한 자, 소정근로시간이 주 30시간 미만인 자, 재택근무자 등은 가입이 제한된다.\\n\\n기업 가입조건은 청년 공제 가입 대상인 청년의 정규직 채용일 기준 고용보험 피보험자 수 5인 이상인 '중소기업기본법' 상 중소기업 또는 '중견기업 성장촉진 및 경쟁력 강화에 관한 법률' 상 중견기업에 해당하는 기업이다. (다만 벤처기업, 청년 창업기업 등 일부는 1인 이상 5인 미만 기업도 가능하다.)\\n\\n\\n\\n신청은 청년내일채움공제 홈페이지에서 가능하며, 정규직 취업일(채용일)로부터 3개월 이내에 이뤄져야 한다.\\n\\n이외 관련 자세한 사항은 청년 내일채움공제 공식 홈페이지에서 확인 할 수 있다.\\n\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1. 문서 타입에 따른 문장 단위로 분리하기(텍스트 크롤링 > 문장 단위 분리 > 명사 추출)\n",
    "#<SentenceTokenizer Class>\n",
    "class SentenceTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "        self.twitter = Twitter()\n",
    "        self.stopwords = ['중인' ,'만큼', '마찬가지', '꼬집었', \"연합뉴스\", \"데일리\", \"동아일보\", \"중앙일보\", \"조선일보\", \"기자\"\n",
    ",\"아\", \"휴\", \"아이구\", \"아이쿠\", \"아이고\", \"어\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\", \"을\", \"를\", \"에\", \"의\", \"가\",]\n",
    "    def url2sentences(self, url):\n",
    "        article = Article(url, language='ko')\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        sentences = self.kkma.sentences(article.text)\n",
    "        \n",
    "        \n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "\n",
    "    \n",
    "    \n",
    "    def text2sentences(self, text):\n",
    "        sentences = self.kkma.sentences(text)\n",
    "        for idx in range(0, len(sentences)):\n",
    "            if len(sentences[idx]) <= 10:\n",
    "                sentences[idx-1] += (' ' + sentences[idx])\n",
    "                sentences[idx] = ''\n",
    "        return sentences\n",
    "    def get_nouns(self, sentences):\n",
    "        nouns = []\n",
    "        for sentence in sentences:\n",
    "            if sentence is not '':\n",
    "                nouns.append(' '.join([noun for noun in self.twitter.nouns(str(sentence))\n",
    "                                       if noun not in self.stopwords and len(noun) > 1]))\n",
    "        return nouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2. TF-IDF 모델 생성 및 그래프 생성\n",
    "#<GrpahMatrix Class>\n",
    "\n",
    "class GraphMatrix(object):\n",
    "    def __init__(self):\n",
    "        self.tfidf = TfidfVectorizer()\n",
    "        self.cnt_vec = CountVectorizer()\n",
    "        self.graph_sentence = []\n",
    "        \n",
    "        \n",
    "        \n",
    "    def build_sent_graph(self, sentence):\n",
    "        tfidf_mat = self.tfidf.fit_transform(sentence).toarray()\n",
    "        self.graph_sentence = np.dot(tfidf_mat, tfidf_mat.T)\n",
    "        return self.graph_sentence\n",
    "    \n",
    "    \n",
    "    \n",
    "    def build_words_graph(self, sentence):\n",
    "        cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
    "        vocab = self.cnt_vec.vocabulary_\n",
    "        return np.dot(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4. TextRank Class 구현\n",
    "#<Rank class>\n",
    "class Rank(object):\n",
    "    def get_ranks(self, graph, d=0.85): # d = damping factor\n",
    "        A = graph\n",
    "        matrix_size = A.shape[0]\n",
    "        for id in range(matrix_size):\n",
    "            A[id, id] = 0 # diagonal 부분을 0으로\n",
    "            link_sum = np.sum(A[:,id]) # A[:, id] = A[:][id]\n",
    "            if link_sum != 0:\n",
    "                A[:, id] /= link_sum\n",
    "                A[:, id] *= -d\n",
    "                A[id, id] = 1\n",
    "        \n",
    "        \n",
    "        B = (1-d) * np.ones((matrix_size, 1))\n",
    "        ranks = np.linalg.solve(A, B) # 연립방정식 Ax = b\n",
    "        return {idx: r[0] for idx, r in enumerate(ranks)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4. TextRank Class 구현\n",
    "\n",
    "class TextRank(object):\n",
    "    def __init__(self, text):\n",
    "        self.sent_tokenize = SentenceTokenizer()\n",
    "        \n",
    "        if text[:5] in ('http:', 'https'):\n",
    "            self.sentences = self.sent_tokenize.url2sentences(text)\n",
    "        \n",
    "        else:\n",
    "            self.sentences = self.sent_tokenize.text2sentences(text)\n",
    "\n",
    "            \n",
    "        self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
    "        \n",
    "        self.graph_matrix = GraphMatrix()\n",
    "        self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)\n",
    "        self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)\n",
    "        \n",
    "        \n",
    "        self.rank = Rank()\n",
    "        self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
    "        self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
    "        \n",
    "        \n",
    "        self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
    "        self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
    "    def summarize(self, sent_num=3):\n",
    "        summary = []\n",
    "        index=[]\n",
    "        for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
    "            index.append(idx)\n",
    "        \n",
    "        index.sort()\n",
    "        for idx in index:\n",
    "            summary.append(self.sentences[idx])\n",
    "        \n",
    "        return summary\n",
    "\n",
    "    \n",
    "    def keywords(self, word_num=10):\n",
    "        rank = Rank()\n",
    "        rank_idx = rank.get_ranks(self.words_graph)\n",
    "        sorted_rank_idx = sorted(rank_idx, key=lambda k: rank_idx[k], reverse=True)\n",
    "        \n",
    "        \n",
    "        keywords = []\n",
    "        index=[]\n",
    "        for idx in sorted_rank_idx[:word_num]:\n",
    "            index.append(idx)\n",
    "        \n",
    "        \n",
    "        #index.sort()\n",
    "        \n",
    "        for idx in index:\n",
    "            keywords.append(self.idx2word[idx])\n",
    "        \n",
    "        return keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\finance\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ 청년 내일채 움 공제 홈페이지 아시아 투데이 서 현 정 기자 = 2일 ' 청년 내일채 움 공제' 가 주목받고 있다.\n",
      "\n",
      "아시아 투데이 서 현 정 기자 = 2일 ' 청년 내일채 움 공제' 가 주목받고 있다.\n",
      "\n",
      "' 청년 내일채 움 공제' 란 중소· 중견기업에 정규직으로 취업한 청년들의 장기 근속을 위해 고용 노동부와 중소 벤처기업 부가 공동으로 운영하는 정책성 공제사업이다.\n",
      "\n",
      "기업 가입조건은 청년 공제 가입 대상인 청년의 정규직 채용 일 기준 고용보험 피보험자 수 5 인 이상인 ' 중소기업 기본법' 상 중소기업 또는 ' 중견기업 성장 촉진 및 경쟁력 강화에 관한 법률' 상 중견기업에 해당하는 기업이다.\n",
      "\n",
      "신청은 청년 내일채 움 공제 홈페이지에서 가능하며, 정규직 취업 일( 채용 일 )로부터 3개월 이내에 이뤄 져야 한다.\n",
      "\n",
      "keywords : ['청년', '가입', '공제', '정규직', '고용', '기업', '보험', '조건', '해당', '취업']\n"
     ]
    }
   ],
   "source": [
    "# Step 5. 결과 확인\n",
    "\n",
    "url = 'http://www.asiatoday.co.kr/view.php?key=20190802000725171'\n",
    "\n",
    "textrank = TextRank(url)\n",
    "\n",
    "for row in textrank.summarize(5):\n",
    "    print(row)\n",
    "    print()\n",
    "\n",
    "\n",
    "print('keywords :',textrank.keywords())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
